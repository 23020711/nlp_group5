{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14252962,"sourceType":"datasetVersion","datasetId":9094066}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"# CELL 1\n!pip install -q torch transformers datasets accelerate peft bitsandbytes sentencepiece sacrebleu rouge_score matplotlib tqdm\n!pip install -q trl==0.8.6 accelerate --no-deps\n!pip install -q sentence-transformers\n!pip install -q --upgrade bitsandbytes transformers accelerate peft\nimport torch\nprint(\"GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T10:36:54.891765Z","iopub.execute_input":"2025-12-22T10:36:54.892072Z","iopub.status.idle":"2025-12-22T10:37:35.653340Z","shell.execute_reply.started":"2025-12-22T10:36:54.892046Z","shell.execute_reply":"2025-12-22T10:37:35.652611Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.2/245.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m103.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.9/380.9 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m556.4/556.4 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntrl 0.8.6 requires tyro>=0.5.11, which is not installed.\u001b[0m\u001b[31m\n\u001b[0mGPU: Tesla T4\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# CELL 2\nfrom datasets import load_dataset, DatasetDict, Dataset\nimport os\n\ndef load_local_text(file_path):\n    if not os.path.exists(file_path):\n        print(f\"Warning: File {file_path} not found.\")\n        return []\n    with open(file_path, 'r', encoding='utf-8') as f:\n        lines = [line.strip() for line in f if line.strip()]\n    return lines\n\ntrain_vi_lines = load_local_text('/kaggle/input/vlspdata/train.vi.txt')\ntrain_en_lines = load_local_text('/kaggle/input/vlspdata/train.en.txt')\ntest_vi_lines = load_local_text('/kaggle/input/vlspdata/public_test.vi (1).txt')\ntest_en_lines = load_local_text('/kaggle/input/vlspdata/public_test.en.txt')\n\nmin_len_train = min(len(train_vi_lines), len(train_en_lines))\ntrain_vi_lines = train_vi_lines[:min_len_train]\ntrain_en_lines = train_en_lines[:min_len_train]\n\nfull_train_dataset = Dataset.from_dict({\"en\": train_en_lines, \"vi\": train_vi_lines})\nsplit_dataset = full_train_dataset.train_test_split(test_size=0.05, seed=42) \ntrain_dataset = split_dataset[\"train\"]\nval_dataset = split_dataset[\"test\"]\n\nmin_len_test = min(len(test_vi_lines), len(test_en_lines))\ntest_dataset = Dataset.from_dict({\"en\": test_en_lines[:min_len_test], \"vi\": test_vi_lines[:min_len_test]})\n\ndataset = DatasetDict({\n    \"train\": train_dataset,\n    \"validation\": val_dataset,\n    \"test\": test_dataset\n})\n\nprint(\"\\nDataset Structure:\")\nprint(dataset)\nprint(f\"Train: {len(dataset['train']):,} pairs\")","metadata":{"colab":{"background_save":true},"id":"zJLMkooRIRKk","outputId":"508cae99-2563-4b04-ac92-9c3438cd6ece","trusted":true,"execution":{"iopub.status.busy":"2025-12-22T10:37:35.654868Z","iopub.execute_input":"2025-12-22T10:37:35.655201Z","iopub.status.idle":"2025-12-22T10:37:42.865787Z","shell.execute_reply.started":"2025-12-22T10:37:35.655175Z","shell.execute_reply":"2025-12-22T10:37:42.865094Z"}},"outputs":[{"name":"stdout","text":"\nDataset Structure:\nDatasetDict({\n    train: Dataset({\n        features: ['en', 'vi'],\n        num_rows: 475000\n    })\n    validation: Dataset({\n        features: ['en', 'vi'],\n        num_rows: 25000\n    })\n    test: Dataset({\n        features: ['en', 'vi'],\n        num_rows: 3000\n    })\n})\nTrain: 475,000 pairs\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# CELL 3\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\nfrom peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\nimport torch\n\nmodel_name = \"Qwen/Qwen2.5-1.5B\"\ntokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token\n\nquant_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.float16,\n    bnb_4bit_use_double_quant=True,\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    quantization_config=quant_config,\n    device_map=\"auto\",\n    torch_dtype=torch.float16,\n    trust_remote_code=True,\n)\n\nmodel = prepare_model_for_kbit_training(model)\n\n# Cấu hình LoRA tối ưu\npeft_config = LoraConfig(\n    r=32, # Tăng rank lên 32 để học tốt hơn các thuật ngữ y tế\n    lora_alpha=64,\n    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n)\n\nmodel = get_peft_model(model, peft_config)\nmodel.print_trainable_parameters()","metadata":{"colab":{"background_save":true},"id":"yatK-0YkIUit","trusted":true,"execution":{"iopub.status.busy":"2025-12-22T10:37:42.866607Z","iopub.execute_input":"2025-12-22T10:37:42.866842Z","iopub.status.idle":"2025-12-22T10:38:36.244561Z","shell.execute_reply.started":"2025-12-22T10:37:42.866821Z","shell.execute_reply":"2025-12-22T10:38:36.243620Z"}},"outputs":[{"name":"stderr","text":"2025-12-22 10:37:53.768946: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1766399874.162388      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1766399874.272379      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1766399875.267842      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766399875.267875      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766399875.267878      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766399875.267880      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1035a755cce14049b51347c0ca05720c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf98b58eb91e42b8ad927c7063962dc9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbdb2ca50b7a4133a26f0a37e3daa7be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af13ae665ca645608a693f217d657853"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e97bd24cbf174f1aa7dd8bd8cbc24fb9"}},"metadata":{}},{"name":"stderr","text":"`torch_dtype` is deprecated! Use `dtype` instead!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/3.09G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c4411219ee84fb1b8e19becccf72216"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/138 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30dd49a40cfa418eb9050e8ff7f0bacb"}},"metadata":{}},{"name":"stdout","text":"trainable params: 36,929,536 || all params: 1,580,643,840 || trainable%: 2.3364\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# CELL 4 - OPTIMIZED FOR SPEED\nfrom transformers import TrainingArguments\nfrom trl import SFTTrainer\nimport torch\nimport random\n\nfull_train = dataset[\"train\"].shuffle(seed=42)\n\ntrain_subset = full_train.select(range(min(100000, len(full_train))))\n\nval_subset = dataset[\"validation\"].shuffle(seed=42).select(range(min(2000, len(dataset[\"validation\"]))))\n\nprint(f\"Training on: {len(train_subset)} samples\")\n\ndef formatting_prompts_func(example):\n    texts = []\n    for en, vi in zip(example[\"en\"], example[\"vi\"]):\n        # Trộn ngẫu nhiên chiều dịch\n        if random.random() < 0.5:\n            text = f\"Translate English to Vietnamese (Medical domain):\\nEnglish: {en.strip()}\\nVietnamese: {vi.strip()}<|im_end|>\"\n        else:\n            text = f\"Translate Vietnamese to English (Medical domain):\\nVietnamese: {vi.strip()}\\nEnglish: {en.strip()}<|im_end|>\"\n        texts.append(text)\n    return {\"text\": texts}\n\nprocessed_train = train_subset.map(formatting_prompts_func, batched=True, remove_columns=[\"en\", \"vi\"], num_proc=4)\nprocessed_val = val_subset.map(formatting_prompts_func, batched=True, remove_columns=[\"en\", \"vi\"], num_proc=4)\n\ntraining_args = TrainingArguments(\n    output_dir=\"./qwen-medical-vlsp\",\n    num_train_epochs=1,\n    \n    per_device_train_batch_size=8,  \n    gradient_accumulation_steps=2,   \n    \n    optim=\"paged_adamw_8bit\",\n    learning_rate=2e-4,\n    fp16=True,\n    bf16=False,\n    warmup_steps=200,\n    logging_steps=50,            \n    eval_strategy=\"steps\",\n    eval_steps=1000,               \n    save_steps=1000,\n    weight_decay=0.01,\n    report_to=\"none\",\n    save_total_limit=2,\n    gradient_checkpointing=True,\n    dataloader_num_workers=2,\n    group_by_length=True,            \n)\n\ntrainer = SFTTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=processed_train,\n    eval_dataset=processed_val,\n    dataset_text_field=\"text\",\n    max_seq_length=512,\n    tokenizer=tokenizer,\n    packing=False, \n)\n\nprint(\"Bắt đầu training với cấu hình tối ưu tốc độ...\")\ntrainer.train()\n\nsave_dir = \"qwen2.5-1.5b-vlsp-final\"\nmodel.save_pretrained(save_dir)\ntokenizer.save_pretrained(save_dir)\nprint(f\"Saved model to {save_dir}\")","metadata":{"colab":{"background_save":true},"id":"M9XLwdI_IWdo","trusted":true,"execution":{"iopub.status.busy":"2025-12-22T10:40:17.311179Z","iopub.execute_input":"2025-12-22T10:40:17.311550Z","iopub.status.idle":"2025-12-22T13:59:23.144339Z","shell.execute_reply.started":"2025-12-22T10:40:17.311494Z","shell.execute_reply":"2025-12-22T13:59:23.143463Z"}},"outputs":[{"name":"stdout","text":"Training on: 100000 samples\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/100000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ab9ae6fa0e64ce693bc903796906cf8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc323934f0964fc2953c89ac2dcd5a9a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06d35b62a2b248dfa07f9995007deb27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0b90d14f2d6438fb6e1d724755cca05"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/trl/trainer/sft_trainer.py:323: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n  super().__init__(\n","output_type":"stream"},{"name":"stdout","text":"Bắt đầu training với cấu hình tối ưu tốc độ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6250' max='6250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6250/6250 3:18:06, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1000</td>\n      <td>1.664100</td>\n      <td>1.675312</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>1.610600</td>\n      <td>1.609338</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>1.573800</td>\n      <td>1.567672</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>1.566800</td>\n      <td>1.535496</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>1.531800</td>\n      <td>1.514541</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>1.483300</td>\n      <td>1.499875</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"Saved model to qwen2.5-1.5b-vlsp-final\n","output_type":"stream"}],"execution_count":5}]}