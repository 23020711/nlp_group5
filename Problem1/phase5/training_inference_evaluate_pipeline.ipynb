{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DX4jFNd_R8LK",
        "outputId": "b56fae0b-e8da-45f8-f71a-f9dcd17fd80a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Running on: cuda\n",
            "Downloading data...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-163462796.py:35: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
            "  tar.extractall(path=DATA_SAVE_PATH)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 133317 sentences.\n",
            "Building Vocab...\n",
            "Vocab Size: Vi=12517, En=29345\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import time\n",
        "import tarfile\n",
        "import html\n",
        "import random\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from google.colab import drive\n",
        "\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "PROJECT_PATH = '/content/drive/MyDrive/NLP_Phase5_Final'\n",
        "CHECKPOINT_PATH = os.path.join(PROJECT_PATH, 'checkpoints')\n",
        "DATA_SAVE_PATH = os.path.join(PROJECT_PATH, 'data')\n",
        "\n",
        "if not os.path.exists(CHECKPOINT_PATH): os.makedirs(CHECKPOINT_PATH)\n",
        "if not os.path.exists(DATA_SAVE_PATH): os.makedirs(DATA_SAVE_PATH)\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Running on: {DEVICE}\")\n",
        "\n",
        "def download_and_clean():\n",
        "    url = \"https://github.com/stefan-it/nmt-en-vi/raw/master/data/train-en-vi.tgz\"\n",
        "    tgz_path = os.path.join(DATA_SAVE_PATH, \"train-en-vi.tgz\")\n",
        "\n",
        "    if not os.path.exists(os.path.join(DATA_SAVE_PATH, \"train.vi\")):\n",
        "        print(\"Downloading data...\")\n",
        "        os.system(f\"wget -q {url} -O {tgz_path}\")\n",
        "        with tarfile.open(tgz_path, \"r:gz\") as tar:\n",
        "            tar.extractall(path=DATA_SAVE_PATH)\n",
        "\n",
        "    def clean_data(path):\n",
        "        with open(path, 'r', encoding='utf-8') as f:\n",
        "            return [html.unescape(line).replace('\\xa0', ' ').strip() for line in f]\n",
        "\n",
        "    src_lines = clean_data(os.path.join(DATA_SAVE_PATH, 'train.vi'))\n",
        "    trg_lines = clean_data(os.path.join(DATA_SAVE_PATH, 'train.en'))\n",
        "    return src_lines, trg_lines\n",
        "\n",
        "src_raw, trg_raw = download_and_clean()\n",
        "print(f\"Loaded {len(src_raw)} sentences.\")\n",
        "\n",
        "def tokenize(text):\n",
        "    return text.lower().split()\n",
        "\n",
        "class Vocabulary:\n",
        "    def __init__(self, freq_threshold=2):\n",
        "        self.itos = {0: \"<pad>\", 1: \"<sos>\", 2: \"<eos>\", 3: \"<unk>\"}\n",
        "        self.stoi = {\"<pad>\": 0, \"<sos>\": 1, \"<eos>\": 2, \"<unk>\": 3}\n",
        "        self.freq_threshold = freq_threshold\n",
        "\n",
        "    def __len__(self): return len(self.itos)\n",
        "\n",
        "    def build_vocabulary(self, sentence_list):\n",
        "        frequencies = Counter()\n",
        "        for sentence in sentence_list:\n",
        "            frequencies.update(tokenize(sentence))\n",
        "\n",
        "        idx = 4\n",
        "        for word, freq in frequencies.items():\n",
        "            if freq >= self.freq_threshold:\n",
        "                self.stoi[word] = idx\n",
        "                self.itos[idx] = word\n",
        "                idx += 1\n",
        "\n",
        "    def numericalize(self, text):\n",
        "        return [self.stoi.get(token, self.stoi[\"<unk>\"]) for token in tokenize(text)]\n",
        "\n",
        "print(\"Building Vocab...\")\n",
        "src_vocab = Vocabulary(freq_threshold=2)\n",
        "trg_vocab = Vocabulary(freq_threshold=2)\n",
        "src_vocab.build_vocabulary(src_raw)\n",
        "trg_vocab.build_vocabulary(trg_raw)\n",
        "print(f\"Vocab Size: Vi={len(src_vocab)}, En={len(trg_vocab)}\")\n",
        "\n",
        "# 4. Dataset & DataLoader\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, src_lines, trg_lines, src_vocab, trg_vocab, max_len=100):\n",
        "        self.src_lines = src_lines\n",
        "        self.trg_lines = trg_lines\n",
        "        self.src_vocab = src_vocab\n",
        "        self.trg_vocab = trg_vocab\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self): return len(self.src_lines)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src_idx = [1] + self.src_vocab.numericalize(self.src_lines[idx]) + [2]\n",
        "        trg_idx = [1] + self.trg_vocab.numericalize(self.trg_lines[idx]) + [2]\n",
        "        # Cắt nếu quá dài\n",
        "        return torch.tensor(src_idx[:self.max_len]), torch.tensor(trg_idx[:self.max_len])\n",
        "\n",
        "def collate_fn(batch):\n",
        "    src_batch, trg_batch = [], []\n",
        "    for src, trg in batch:\n",
        "        src_batch.append(src)\n",
        "        trg_batch.append(trg)\n",
        "    src_pad = torch.nn.utils.rnn.pad_sequence(src_batch, padding_value=0, batch_first=True)\n",
        "    trg_pad = torch.nn.utils.rnn.pad_sequence(trg_batch, padding_value=0, batch_first=True)\n",
        "    return src_pad, trg_pad\n",
        "\n",
        "train_loader = DataLoader(TranslationDataset(src_raw, trg_raw, src_vocab, trg_vocab),\n",
        "                          batch_size=32, shuffle=True, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "op8GiUINR9fF"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, :x.size(1)]\n",
        "        return x\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, n_head):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.d_head = d_model // n_head\n",
        "        self.n_head = n_head\n",
        "        self.d_model = d_model\n",
        "\n",
        "        self.w_q = nn.Linear(d_model, d_model)\n",
        "        self.w_k = nn.Linear(d_model, d_model)\n",
        "        self.w_v = nn.Linear(d_model, d_model)\n",
        "        self.fc_out = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        batch_size = query.shape[0]\n",
        "        Q = self.w_q(query).view(batch_size, -1, self.n_head, self.d_head).permute(0, 2, 1, 3)\n",
        "        K = self.w_k(key).view(batch_size, -1, self.n_head, self.d_head).permute(0, 2, 1, 3)\n",
        "        V = self.w_v(value).view(batch_size, -1, self.n_head, self.d_head).permute(0, 2, 1, 3)\n",
        "\n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / math.sqrt(self.d_head)\n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "        attention = torch.softmax(energy, dim=-1)\n",
        "        x = torch.matmul(attention, V)\n",
        "        x = x.permute(0, 2, 1, 3).contiguous().view(batch_size, -1, self.d_model)\n",
        "        return self.fc_out(x)\n",
        "\n",
        "class PositionwiseFeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff):\n",
        "        super(PositionwiseFeedForward, self).__init__()\n",
        "        self.fc1 = nn.Linear(d_model, d_ff)\n",
        "        self.fc2 = nn.Linear(d_ff, d_model)\n",
        "        self.relu = nn.ReLU()\n",
        "    def forward(self, x):\n",
        "        return self.fc2(self.relu(self.fc1(x)))\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, n_head, d_ff, dropout):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, n_head)\n",
        "        self.ffn = PositionwiseFeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        _src = self.self_attn(src, src, src, src_mask)\n",
        "        src = self.norm1(src + self.dropout(_src))\n",
        "        _src = self.ffn(src)\n",
        "        src = self.norm2(src + self.dropout(_src))\n",
        "        return src\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, n_head, d_ff, dropout):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, n_head)\n",
        "        self.cross_attn = MultiHeadAttention(d_model, n_head)\n",
        "        self.ffn = PositionwiseFeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        _trg = self.self_attn(trg, trg, trg, trg_mask)\n",
        "        trg = self.norm1(trg + self.dropout(_trg))\n",
        "        _trg = self.cross_attn(trg, enc_src, enc_src, src_mask)\n",
        "        trg = self.norm2(trg + self.dropout(_trg))\n",
        "        _trg = self.ffn(trg)\n",
        "        trg = self.norm3(trg + self.dropout(_trg))\n",
        "        return trg\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, src_vocab_size, trg_vocab_size, d_model=256, n_head=8, n_layer=3, d_ff=512, dropout=0.1, max_len=150):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.encoder = nn.ModuleList([EncoderLayer(d_model, n_head, d_ff, dropout) for _ in range(n_layer)])\n",
        "        self.decoder = nn.ModuleList([DecoderLayer(d_model, n_head, d_ff, dropout) for _ in range(n_layer)])\n",
        "\n",
        "        self.src_embedding = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.trg_embedding = nn.Embedding(trg_vocab_size, d_model)\n",
        "        self.pos_encoding = PositionalEncoding(d_model, max_len)\n",
        "        self.fc_out = nn.Linear(d_model, trg_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.src_pad_idx = 0\n",
        "        self.trg_pad_idx = 0\n",
        "\n",
        "    def make_src_mask(self, src):\n",
        "        return (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "    def make_trg_mask(self, trg):\n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "        trg_len = trg.shape[1]\n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device=trg.device)).bool()\n",
        "        return trg_pad_mask & trg_sub_mask\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "\n",
        "        src = self.dropout(self.pos_encoding(self.src_embedding(src)))\n",
        "        for layer in self.encoder:\n",
        "            src = layer(src, src_mask)\n",
        "\n",
        "        trg = self.dropout(self.pos_encoding(self.trg_embedding(trg)))\n",
        "        for layer in self.decoder:\n",
        "            trg = layer(trg, src, trg_mask, src_mask)\n",
        "\n",
        "        return self.fc_out(trg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfm2ndVMR_tp",
        "outputId": "90f8ae07-39ec-4ecb-ba36-1f34d9426695"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Training Phase 5 (Safe Config)... Params: 22,212,001\n",
            "Epoch 01 | Time: 5.6m | Loss: 2.2363\n",
            "Epoch 02 | Time: 5.7m | Loss: 1.9118\n",
            "Epoch 03 | Time: 5.7m | Loss: 1.7639\n",
            "Epoch 04 | Time: 5.7m | Loss: 1.6441\n",
            "Epoch 05 | Time: 5.6m | Loss: 1.5742\n",
            "Epoch 06 | Time: 5.7m | Loss: 1.5200\n",
            "Epoch 07 | Time: 5.7m | Loss: 1.4793\n",
            "Epoch 08 | Time: 5.7m | Loss: 1.4502\n",
            "Epoch 09 | Time: 5.7m | Loss: 1.4258\n",
            "Epoch 10 | Time: 5.7m | Loss: 1.4110\n"
          ]
        }
      ],
      "source": [
        "class NoamScheduler:\n",
        "    def __init__(self, optimizer, d_model, warmup_steps=4000, factor=1.0):\n",
        "        self.optimizer = optimizer\n",
        "        self.d_model = d_model\n",
        "        self.warmup_steps = warmup_steps\n",
        "        self.factor = factor\n",
        "        self.step_num = 0\n",
        "\n",
        "    def step(self):\n",
        "        self.step_num += 1\n",
        "        lr = self.factor * (self.d_model ** -0.5) * min(self.step_num ** -0.5, self.step_num * (self.warmup_steps ** -1.5))\n",
        "        for p in self.optimizer.param_groups:\n",
        "            p['lr'] = lr\n",
        "\n",
        "class LabelSmoothingLoss(nn.Module):\n",
        "    def __init__(self, classes, padding_idx, smoothing=0.1):\n",
        "        super(LabelSmoothingLoss, self).__init__()\n",
        "        self.confidence = 1.0 - smoothing\n",
        "        self.smoothing = smoothing\n",
        "        self.cls = classes\n",
        "        self.padding_idx = padding_idx\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        pred = pred.log_softmax(dim=-1)\n",
        "        with torch.no_grad():\n",
        "            true_dist = torch.zeros_like(pred)\n",
        "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
        "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
        "            true_dist[:, self.padding_idx] = 0\n",
        "            mask = torch.nonzero(target.data == self.padding_idx)\n",
        "            if mask.dim() > 0: true_dist.index_fill_(0, mask.squeeze(), 0.0)\n",
        "        return torch.mean(torch.sum(-true_dist * pred, dim=-1))\n",
        "\n",
        "D_MODEL = 256\n",
        "model = Transformer(len(src_vocab), len(trg_vocab), d_model=D_MODEL, n_head=8, n_layer=3).to(DEVICE)\n",
        "\n",
        "def init_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)\n",
        "model.apply(init_weights)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9)\n",
        "scheduler = NoamScheduler(optimizer, d_model=D_MODEL, warmup_steps=4000)\n",
        "criterion = LabelSmoothingLoss(len(trg_vocab), padding_idx=0, smoothing=0.1)\n",
        "\n",
        "EPOCHS = 10\n",
        "print(f\"Starting Training Phase 5 (Safe Config)... Params: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    for src, trg in train_loader:\n",
        "        src, trg = src.to(DEVICE), trg.to(DEVICE)\n",
        "\n",
        "        trg_input = trg[:, :-1]\n",
        "        trg_output = trg[:, 1:]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, trg_input)\n",
        "\n",
        "        output = output.contiguous().view(-1, output.shape[-1])\n",
        "        trg_output = trg_output.contiguous().view(-1)\n",
        "\n",
        "        loss = criterion(output, trg_output)\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1:02} | Time: {(time.time()-start_time)/60:.1f}m | Loss: {epoch_loss/len(train_loader):.4f}\")\n",
        "\n",
        "    # Save checkpoint\n",
        "    torch.save(model.state_dict(), os.path.join(CHECKPOINT_PATH, 'phase5_safe_best.pt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eV2Zpq4LSDID",
        "outputId": "65c1124a-f813-4725-a244-cbfcf305bbf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Testing Beam Search ---\n",
            "SRC: Tôi là sinh viên\n",
            "PRED: i 'm students .\n"
          ]
        }
      ],
      "source": [
        "def beam_search_decode(model, src_sentence, src_vocab, trg_vocab, device, beam_width=3, max_len=50):\n",
        "    model.eval()\n",
        "\n",
        "    tokens = [1] + src_vocab.numericalize(src_sentence) + [2]\n",
        "    src_tensor = torch.LongTensor(tokens).unsqueeze(0).to(device)\n",
        "    src_mask = model.make_src_mask(src_tensor)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        src_emb = model.dropout(model.pos_encoding(model.src_embedding(src_tensor)))\n",
        "        enc_src = src_emb\n",
        "        for layer in model.encoder:\n",
        "            enc_src = layer(enc_src, src_mask)\n",
        "\n",
        "    sequences = [([1], 0.0, False)]\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        all_candidates = []\n",
        "\n",
        "        for seq, score, finished in sequences:\n",
        "            if finished:\n",
        "                all_candidates.append((seq, score, True))\n",
        "                continue\n",
        "\n",
        "            trg_tensor = torch.LongTensor(seq).unsqueeze(0).to(device)\n",
        "            trg_mask = model.make_trg_mask(trg_tensor)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                trg_emb = model.dropout(model.pos_encoding(model.trg_embedding(trg_tensor)))\n",
        "                out = trg_emb\n",
        "                for layer in model.decoder:\n",
        "                    out = layer(out, enc_src, trg_mask, src_mask)\n",
        "                output = model.fc_out(out)\n",
        "\n",
        "            prob = output[:, -1, :].log_softmax(dim=-1)\n",
        "            topk_probs, topk_idxs = prob.topk(beam_width)\n",
        "\n",
        "            for i in range(beam_width):\n",
        "                token = topk_idxs[0][i].item()\n",
        "                token_prob = topk_probs[0][i].item()\n",
        "\n",
        "                new_seq = seq + [token]\n",
        "                new_score = score + token_prob\n",
        "\n",
        "                if token == 2: # EOS\n",
        "                    all_candidates.append((new_seq, new_score, True))\n",
        "                else:\n",
        "                    all_candidates.append((new_seq, new_score, False))\n",
        "\n",
        "        ordered = sorted(all_candidates, key=lambda x: x[1] / (len(x[0])**0.7), reverse=True)\n",
        "        sequences = ordered[:beam_width]\n",
        "\n",
        "        if all([s[2] for s in sequences]):\n",
        "            break\n",
        "\n",
        "    best_seq = sequences[0][0]\n",
        "\n",
        "    words = []\n",
        "    for idx in best_seq:\n",
        "        if idx not in [0, 1, 2, 3]:\n",
        "            words.append(trg_vocab.itos[idx])\n",
        "\n",
        "    return \" \".join(words)\n",
        "\n",
        "print(\"\\n--- Testing Beam Search ---\")\n",
        "test_sentence = \"Tôi là sinh viên\"\n",
        "print(f\"SRC: {test_sentence}\")\n",
        "print(f\"PRED: {beam_search_decode(model, test_sentence, src_vocab, trg_vocab, DEVICE, beam_width=3)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vC_l15xwSFEg",
        "outputId": "9a118fe0-abf3-4b23-81a3-7c636d9eb114"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Test Data...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-4109901455.py:7: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
            "  with tarfile.open(\"test.tgz\", \"r:gz\") as tar: tar.extractall()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating Beam Search on 1268 sentences...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1268/1268 [05:58<00:00,  3.54it/s]\n",
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "FINAL BLEU SCORE: 13.96\n"
          ]
        }
      ],
      "source": [
        "!pip install -q sacrebleu tqdm\n",
        "import sacrebleu\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(\"Downloading Test Data...\")\n",
        "os.system(\"wget -q https://github.com/stefan-it/nmt-en-vi/raw/master/data/test-2013-en-vi.tgz -O test.tgz\")\n",
        "with tarfile.open(\"test.tgz\", \"r:gz\") as tar: tar.extractall()\n",
        "\n",
        "def clean_file(path):\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        return [html.unescape(line).strip() for line in f]\n",
        "\n",
        "test_src = clean_file('tst2013.vi')\n",
        "test_ref = clean_file('tst2013.en')\n",
        "\n",
        "hypotheses = []\n",
        "print(f\"Evaluating Beam Search on {len(test_src)} sentences...\")\n",
        "\n",
        "for sent in tqdm(test_src):\n",
        "    pred = beam_search_decode(model, sent, src_vocab, trg_vocab, DEVICE, beam_width=3)\n",
        "    hypotheses.append(pred)\n",
        "\n",
        "bleu = sacrebleu.corpus_bleu(hypotheses, [test_ref], tokenize='13a')\n",
        "print(f\"\\nFINAL BLEU SCORE: {bleu.score:.2f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
