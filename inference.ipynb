{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# 1. KET NOI GOOGLE DRIVE\n",
        "# Neu da mount roi thi co the bo qua dong nay\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "# Cau hinh duong dan (Phai khop voi luc train)\n",
        "PROJECT_PATH = '/content/drive/MyDrive/NLP_Assignment_2025'\n",
        "DATA_PATH = os.path.join(PROJECT_PATH, 'data')\n",
        "CHECKPOINT_PATH = os.path.join(PROJECT_PATH, 'checkpoints')\n",
        "MODEL_FILE = os.path.join(CHECKPOINT_PATH, 'transformer_best.pt')\n",
        "\n",
        "# Kiem tra file ton tai\n",
        "if not os.path.exists(MODEL_FILE):\n",
        "    print(f\"ERROR: Khong tim thay file model tai {MODEL_FILE}\")\n",
        "else:\n",
        "    print(f\"Tim thay model tai: {MODEL_FILE}\")\n",
        "\n",
        "# 2. DINH NGHIA LAI CAC CLASS (BAT BUOC)\n",
        "# Phai giong het luc train de load duoc weights\n",
        "\n",
        "# --- Class Vocabulary ---\n",
        "class Vocabulary:\n",
        "    def __init__(self, freq_threshold=2):\n",
        "        self.itos = {0: \"<unk>\", 1: \"<pad>\", 2: \"<sos>\", 3: \"<eos>\"}\n",
        "        self.stoi = {\"<unk>\": 0, \"<pad>\": 1, \"<sos>\": 2, \"<eos>\": 3}\n",
        "        self.freq_threshold = freq_threshold\n",
        "\n",
        "    def __len__(self): return len(self.itos)\n",
        "\n",
        "    def numericalize(self, text):\n",
        "        return [self.stoi.get(token, self.stoi[\"<unk>\"]) for token in text.lower().strip().split()]\n",
        "\n",
        "# --- Class Model Components ---\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, :x.size(1)]\n",
        "        return x\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, n_head):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.d_head = d_model // n_head\n",
        "        self.n_head = n_head\n",
        "        self.d_model = d_model\n",
        "\n",
        "        self.w_q = nn.Linear(d_model, d_model)\n",
        "        self.w_k = nn.Linear(d_model, d_model)\n",
        "        self.w_v = nn.Linear(d_model, d_model)\n",
        "        self.fc_out = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        batch_size = query.shape[0]\n",
        "        Q = self.w_q(query).view(batch_size, -1, self.n_head, self.d_head).permute(0, 2, 1, 3)\n",
        "        K = self.w_k(key).view(batch_size, -1, self.n_head, self.d_head).permute(0, 2, 1, 3)\n",
        "        V = self.w_v(value).view(batch_size, -1, self.n_head, self.d_head).permute(0, 2, 1, 3)\n",
        "\n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / math.sqrt(self.d_head)\n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "        attention = torch.softmax(energy, dim=-1)\n",
        "        x = torch.matmul(attention, V)\n",
        "        x = x.permute(0, 2, 1, 3).contiguous().view(batch_size, -1, self.d_model)\n",
        "        return self.fc_out(x)\n",
        "\n",
        "class PositionwiseFeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff):\n",
        "        super(PositionwiseFeedForward, self).__init__()\n",
        "        self.fc1 = nn.Linear(d_model, d_ff)\n",
        "        self.fc2 = nn.Linear(d_ff, d_model)\n",
        "        self.relu = nn.ReLU()\n",
        "    def forward(self, x):\n",
        "        return self.fc2(self.relu(self.fc1(x)))\n",
        "\n",
        "# --- Class Transformer Architecture ---\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, n_head, d_ff, dropout):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, n_head)\n",
        "        self.ffn = PositionwiseFeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    def forward(self, src, src_mask):\n",
        "        _src = self.self_attn(src, src, src, src_mask)\n",
        "        src = self.norm1(src + self.dropout(_src))\n",
        "        _src = self.ffn(src)\n",
        "        src = self.norm2(src + self.dropout(_src))\n",
        "        return src\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, n_head, d_ff, dropout):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, n_head)\n",
        "        self.cross_attn = MultiHeadAttention(d_model, n_head)\n",
        "        self.ffn = PositionwiseFeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        _trg = self.self_attn(trg, trg, trg, trg_mask)\n",
        "        trg = self.norm1(trg + self.dropout(_trg))\n",
        "        _trg = self.cross_attn(trg, enc_src, enc_src, src_mask)\n",
        "        trg = self.norm2(trg + self.dropout(_trg))\n",
        "        _trg = self.ffn(trg)\n",
        "        trg = self.norm3(trg + self.dropout(_trg))\n",
        "        return trg\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, d_model, n_layer, n_head, d_ff, dropout, max_len):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, d_model)\n",
        "        self.pos_encoding = PositionalEncoding(d_model, max_len)\n",
        "        self.layers = nn.ModuleList([EncoderLayer(d_model, n_head, d_ff, dropout) for _ in range(n_layer)])\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    def forward(self, src, src_mask):\n",
        "        src = self.dropout(self.pos_encoding(self.embedding(src)))\n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask)\n",
        "        return src\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, d_model, n_layer, n_head, d_ff, dropout, max_len):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_dim, d_model)\n",
        "        self.pos_encoding = PositionalEncoding(d_model, max_len)\n",
        "        self.layers = nn.ModuleList([DecoderLayer(d_model, n_head, d_ff, dropout) for _ in range(n_layer)])\n",
        "        self.fc_out = nn.Linear(d_model, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        trg = self.dropout(self.pos_encoding(self.embedding(trg)))\n",
        "        for layer in self.layers:\n",
        "            trg = layer(trg, enc_src, trg_mask, src_mask)\n",
        "        output = self.fc_out(trg)\n",
        "        return output\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, src_vocab_size, trg_vocab_size, d_model=256, n_head=8, n_layer=3, d_ff=512, dropout=0.1, max_len=100, src_pad_idx=1, trg_pad_idx=1):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "        self.encoder = Encoder(src_vocab_size, d_model, n_layer, n_head, d_ff, dropout, max_len)\n",
        "        self.decoder = Decoder(trg_vocab_size, d_model, n_layer, n_head, d_ff, dropout, max_len)\n",
        "\n",
        "    def make_src_mask(self, src):\n",
        "        return (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "    def make_trg_mask(self, trg):\n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "        trg_len = trg.shape[1]\n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device=trg.device)).bool()\n",
        "        return trg_pad_mask & trg_sub_mask\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "        output = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "        return output\n",
        "\n",
        "# 3. HAM DICH (INFERENCE FUNCTION)\n",
        "UNK_IDX, PAD_IDX, SOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def translate_sentence(sentence, src_vocab, trg_vocab, model, device, max_len=50):\n",
        "    model.eval()\n",
        "\n",
        "    # Xu ly cau dau vao\n",
        "    tokens = [token.lower() for token in sentence.split()]\n",
        "    tokens = [SOS_IDX] + [src_vocab.stoi.get(token, UNK_IDX) for token in tokens] + [EOS_IDX]\n",
        "    src_tensor = torch.LongTensor(tokens).unsqueeze(0).to(device)\n",
        "    src_mask = model.make_src_mask(src_tensor)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Encoder\n",
        "        enc_src = model.encoder(src_tensor, src_mask)\n",
        "\n",
        "        # Decoder (Greedy Search)\n",
        "        trg_indices = [SOS_IDX]\n",
        "        for i in range(max_len):\n",
        "            trg_tensor = torch.LongTensor(trg_indices).unsqueeze(0).to(device)\n",
        "            trg_mask = model.make_trg_mask(trg_tensor)\n",
        "\n",
        "            output = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
        "\n",
        "            # Lay token du doan cuoi cung\n",
        "            pred_token = output.argmax(2)[:,-1].item()\n",
        "            trg_indices.append(pred_token)\n",
        "\n",
        "            if pred_token == EOS_IDX:\n",
        "                break\n",
        "\n",
        "    # Chuyen index ve chu\n",
        "    trg_tokens = [trg_vocab.itos[i] for i in trg_indices]\n",
        "\n",
        "    # Loai bo SOS va EOS khi in ra\n",
        "    result = []\n",
        "    for token in trg_tokens:\n",
        "        if token not in [\"<sos>\", \"<eos>\", \"<pad>\"]:\n",
        "            result.append(token)\n",
        "\n",
        "    return \" \".join(result)\n",
        "\n",
        "# 4. CHAY THU (MAIN INFERENCE) - DA SUA LOI WEIGHTS ONLY\n",
        "print(\"Dang load Vocab va Model...\")\n",
        "try:\n",
        "    # Load Vocab (Them weights_only=False de cho phep load class Vocabulary)\n",
        "    src_vocab = torch.load(os.path.join(DATA_PATH, 'src_vocab.pth'), weights_only=False)\n",
        "    trg_vocab = torch.load(os.path.join(DATA_PATH, 'trg_vocab.pth'), weights_only=False)\n",
        "\n",
        "    # Khoi tao Model\n",
        "    INPUT_DIM = len(src_vocab)\n",
        "    OUTPUT_DIM = len(trg_vocab)\n",
        "\n",
        "    # Cac thong so nay phai khop voi luc train\n",
        "    D_MODEL = 256\n",
        "    N_HEAD = 8\n",
        "    N_LAYER = 3\n",
        "    D_FF = 512\n",
        "    DROPOUT = 0.1\n",
        "    MAX_LEN = 150\n",
        "\n",
        "    model = Transformer(INPUT_DIM, OUTPUT_DIM, D_MODEL, N_HEAD, N_LAYER, D_FF, DROPOUT, MAX_LEN, PAD_IDX, PAD_IDX)\n",
        "\n",
        "    # Load Weights (Them weights_only=True hoac False deu duoc vi day la state_dict)\n",
        "    # De an toan va tranh loi tuong tu, ta de weights_only=False cho dong nhat\n",
        "    if torch.cuda.is_available():\n",
        "        map_location = torch.device('cuda')\n",
        "    else:\n",
        "        map_location = torch.device('cpu')\n",
        "\n",
        "    state_dict = torch.load(MODEL_FILE, map_location=map_location, weights_only=False)\n",
        "    model.load_state_dict(state_dict)\n",
        "\n",
        "    model = model.to(DEVICE)\n",
        "    print(\"Load Model thanh cong!\")\n",
        "\n",
        "    # Test dich\n",
        "    sentences = [\n",
        "        \"tôi là sinh viên\",\n",
        "        \"hôm nay trời đẹp\",\n",
        "        \"cảm ơn bạn rất nhiều\",\n",
        "        \"tôi đi học bằng xe buýt\"\n",
        "    ]\n",
        "\n",
        "    print(\"\\n--- KET QUA DICH THU ---\")\n",
        "    for s in sentences:\n",
        "        translated = translate_sentence(s, src_vocab, trg_vocab, model, DEVICE)\n",
        "        print(f\"Input : {s}\")\n",
        "        print(f\"Output: {translated}\")\n",
        "        print(\"-\" * 30)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Loi xay ra: {e}\")\n",
        "    print(\"Hay kiem tra lai duong dan file trong Drive.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5STbqm9LoBjP",
        "outputId": "14d8a43e-c9c6-45f2-dcb8-9dbd0c80e207"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tim thay model tai: /content/drive/MyDrive/NLP_Assignment_2025/checkpoints/transformer_best.pt\n",
            "Dang load Vocab va Model...\n",
            "Load Model thanh cong!\n",
            "\n",
            "--- KET QUA DICH THU ---\n",
            "Input : tôi là sinh viên\n",
            "Output: i was a student .\n",
            "------------------------------\n",
            "Input : hôm nay trời đẹp\n",
            "Output: today &apos;s the sun .\n",
            "------------------------------\n",
            "Input : cảm ơn bạn rất nhiều\n",
            "Output: thank you very much .\n",
            "------------------------------\n",
            "Input : tôi đi học bằng xe buýt\n",
            "Output: i went to the bus .\n",
            "------------------------------\n"
          ]
        }
      ]
    }
  ]
}