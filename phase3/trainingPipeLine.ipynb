{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DX4jFNd_R8LK",
        "outputId": "ed03e3ce-569a-4d6b-8b93-857c35308ce6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Phase 3 Setup Complete. Saving to: /content/drive/MyDrive/NLP_Assignment_2025(phase3)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m100.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m92.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m142.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import html\n",
        "from google.colab import drive\n",
        "\n",
        "# 1. Mount Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "PROJECT_PATH = '/content/drive/MyDrive/NLP_Assignment_2025(phase3)'\n",
        "CHECKPOINT_PATH = os.path.join(PROJECT_PATH, 'checkpoints')\n",
        "DATA_SAVE_PATH = os.path.join(PROJECT_PATH, 'data')\n",
        "\n",
        "if not os.path.exists(CHECKPOINT_PATH): os.makedirs(CHECKPOINT_PATH)\n",
        "if not os.path.exists(DATA_SAVE_PATH): os.makedirs(DATA_SAVE_PATH)\n",
        "\n",
        "print(f\"Phase 3 Setup Complete. Saving to: {PROJECT_PATH}\")\n",
        "\n",
        "!pip install -q pyvi spacy torchtext tokenizers\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "op8GiUINR9fF",
        "outputId": "13dd1361-cb37-43c6-cec4-665e7b7897f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data...\n",
            "Extracting data...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1924179185.py:24: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
            "  tar.extractall(path=data_dir)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data ready at: data\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tarfile\n",
        "import sys\n",
        "\n",
        "def download_real_data():\n",
        "    data_dir = 'data'\n",
        "    if not os.path.exists(data_dir): os.makedirs(data_dir)\n",
        "\n",
        "    url = \"https://github.com/stefan-it/nmt-en-vi/raw/master/data/train-en-vi.tgz\"\n",
        "    tgz_path = os.path.join(data_dir, \"train-en-vi.tgz\")\n",
        "    expected_vi = os.path.join(data_dir, \"train.vi\")\n",
        "    expected_en = os.path.join(data_dir, \"train.en\")\n",
        "\n",
        "    if os.path.exists(expected_vi) and os.path.exists(expected_en):\n",
        "        if os.path.getsize(expected_vi) > 0:\n",
        "            print(\"Data already exists. Skipping download.\")\n",
        "            return\n",
        "\n",
        "    print(\"Downloading data...\")\n",
        "    os.system(f\"wget -q {url} -O {tgz_path}\")\n",
        "\n",
        "    print(\"Extracting data...\")\n",
        "    with tarfile.open(tgz_path, \"r:gz\") as tar:\n",
        "        tar.extractall(path=data_dir)\n",
        "\n",
        "    print(f\"Data ready at: {data_dir}\")\n",
        "\n",
        "download_real_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kfm2ndVMR_tp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, :x.size(1)]\n",
        "        return x\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, n_head):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        assert d_model % n_head == 0, \"d_model must be divisible by n_head\"\n",
        "        self.d_head = d_model // n_head\n",
        "        self.n_head = n_head\n",
        "        self.d_model = d_model\n",
        "        self.w_q = nn.Linear(d_model, d_model)\n",
        "        self.w_k = nn.Linear(d_model, d_model)\n",
        "        self.w_v = nn.Linear(d_model, d_model)\n",
        "        self.fc_out = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        batch_size = query.shape[0]\n",
        "        Q = self.w_q(query).view(batch_size, -1, self.n_head, self.d_head).permute(0, 2, 1, 3)\n",
        "        K = self.w_k(key).view(batch_size, -1, self.n_head, self.d_head).permute(0, 2, 1, 3)\n",
        "        V = self.w_v(value).view(batch_size, -1, self.n_head, self.d_head).permute(0, 2, 1, 3)\n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / math.sqrt(self.d_head)\n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, -1e9)\n",
        "        attention = torch.softmax(energy, dim=-1)\n",
        "        x = torch.matmul(attention, V)\n",
        "        x = x.permute(0, 2, 1, 3).contiguous().view(batch_size, -1, self.d_model)\n",
        "        return self.fc_out(x)\n",
        "\n",
        "class PositionwiseFeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff):\n",
        "        super(PositionwiseFeedForward, self).__init__()\n",
        "        self.fc1 = nn.Linear(d_model, d_ff)\n",
        "        self.fc2 = nn.Linear(d_ff, d_model)\n",
        "        self.relu = nn.ReLU()\n",
        "    def forward(self, x):\n",
        "        return self.fc2(self.relu(self.fc1(x)))\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, n_head, d_ff, dropout):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, n_head)\n",
        "        self.ffn = PositionwiseFeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    def forward(self, src, src_mask):\n",
        "        _src = self.self_attn(src, src, src, src_mask)\n",
        "        src = self.norm1(src + self.dropout(_src))\n",
        "        _src = self.ffn(src)\n",
        "        src = self.norm2(src + self.dropout(_src))\n",
        "        return src\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, n_head, d_ff, dropout):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, n_head)\n",
        "        self.cross_attn = MultiHeadAttention(d_model, n_head)\n",
        "        self.ffn = PositionwiseFeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        _trg = self.self_attn(trg, trg, trg, trg_mask)\n",
        "        trg = self.norm1(trg + self.dropout(_trg))\n",
        "        _trg = self.cross_attn(trg, enc_src, enc_src, src_mask)\n",
        "        trg = self.norm2(trg + self.dropout(_trg))\n",
        "        _trg = self.ffn(trg)\n",
        "        trg = self.norm3(trg + self.dropout(_trg))\n",
        "        return trg\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, d_model, n_layer, n_head, d_ff, dropout, max_len):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, d_model)\n",
        "        self.pos_encoding = PositionalEncoding(d_model, max_len)\n",
        "        self.layers = nn.ModuleList([EncoderLayer(d_model, n_head, d_ff, dropout) for _ in range(n_layer)])\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    def forward(self, src, src_mask):\n",
        "        src = self.dropout(self.pos_encoding(self.embedding(src)))\n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask)\n",
        "        return src\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, d_model, n_layer, n_head, d_ff, dropout, max_len):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_dim, d_model)\n",
        "        self.pos_encoding = PositionalEncoding(d_model, max_len)\n",
        "        self.layers = nn.ModuleList([DecoderLayer(d_model, n_head, d_ff, dropout) for _ in range(n_layer)])\n",
        "        self.fc_out = nn.Linear(d_model, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        trg = self.dropout(self.pos_encoding(self.embedding(trg)))\n",
        "        for layer in self.layers:\n",
        "            trg = layer(trg, enc_src, trg_mask, src_mask)\n",
        "        output = self.fc_out(trg)\n",
        "        return output\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, src_vocab_size, trg_vocab_size, d_model=256, n_head=8, n_layer=3, d_ff=512, dropout=0.1, max_len=100, src_pad_idx=1, trg_pad_idx=1):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "        self.encoder = Encoder(src_vocab_size, d_model, n_layer, n_head, d_ff, dropout, max_len)\n",
        "        self.decoder = Decoder(trg_vocab_size, d_model, n_layer, n_head, d_ff, dropout, max_len)\n",
        "    def make_src_mask(self, src):\n",
        "        return (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "    def make_trg_mask(self, trg):\n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "        trg_len = trg.shape[1]\n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device=trg.device)).bool()\n",
        "        return trg_pad_mask & trg_sub_mask\n",
        "    def forward(self, src, trg):\n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "        output = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfmwSa3ASCOG",
        "outputId": "0eea0b4a-b2b5-4cbc-cfc1-17770dfce999"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cleaning train.vi: 133317it [00:00, 171707.46it/s]\n",
            "Cleaning train.en: 133317it [00:00, 253828.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Source Tokenizer (BPE)...\n",
            "Training Target Tokenizer (BPE)...\n",
            "BPE Tokenizers Saved!\n"
          ]
        }
      ],
      "source": [
        "from tokenizers import ByteLevelBPETokenizer\n",
        "from tokenizers.processors import BertProcessing\n",
        "import os\n",
        "import html\n",
        "from tqdm import tqdm\n",
        "\n",
        "def clean_file(raw_path, clean_path):\n",
        "    with open(raw_path, 'r', encoding='utf-8') as f_in, open(clean_path, 'w', encoding='utf-8') as f_out:\n",
        "        for line in tqdm(f_in, desc=f\"Cleaning {os.path.basename(raw_path)}\"):\n",
        "            clean_line = html.unescape(line).replace('\\xa0', ' ').strip()\n",
        "            if clean_line:\n",
        "                f_out.write(clean_line + \"\\n\")\n",
        "    return clean_path\n",
        "\n",
        "if not os.path.exists('data/clean_vi.txt'):\n",
        "    clean_file('data/train.vi', 'data/clean_vi.txt')\n",
        "if not os.path.exists('data/clean_en.txt'):\n",
        "    clean_file('data/train.en', 'data/clean_en.txt')\n",
        "\n",
        "print(\"Training Source Tokenizer (BPE)...\")\n",
        "src_tokenizer = ByteLevelBPETokenizer()\n",
        "src_tokenizer.train(files=[\"data/clean_vi.txt\"], vocab_size=10000, min_frequency=2, special_tokens=[\"<pad>\", \"<sos>\", \"<eos>\", \"<unk>\"])\n",
        "src_tokenizer.save_model(DATA_SAVE_PATH, \"src_bpe\")\n",
        "\n",
        "print(\"Training Target Tokenizer (BPE)...\")\n",
        "trg_tokenizer = ByteLevelBPETokenizer()\n",
        "trg_tokenizer.train(files=[\"data/clean_en.txt\"], vocab_size=10000, min_frequency=2, special_tokens=[\"<pad>\", \"<sos>\", \"<eos>\", \"<unk>\"])\n",
        "trg_tokenizer.save_model(DATA_SAVE_PATH, \"trg_bpe\")\n",
        "\n",
        "print(\"BPE Tokenizers Saved!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eV2Zpq4LSDID",
        "outputId": "7140874f-3e28-4925-9389-cc22064910f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data from data/clean_vi.txt...\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tokenizers import ByteLevelBPETokenizer\n",
        "from tokenizers.processors import TemplateProcessing\n",
        "\n",
        "# Load Tokenizer đã train\n",
        "src_tokenizer = ByteLevelBPETokenizer(\n",
        "    os.path.join(DATA_SAVE_PATH, \"src_bpe-vocab.json\"),\n",
        "    os.path.join(DATA_SAVE_PATH, \"src_bpe-merges.txt\")\n",
        ")\n",
        "trg_tokenizer = ByteLevelBPETokenizer(\n",
        "    os.path.join(DATA_SAVE_PATH, \"trg_bpe-vocab.json\"),\n",
        "    os.path.join(DATA_SAVE_PATH, \"trg_bpe-merges.txt\")\n",
        ")\n",
        "\n",
        "src_tokenizer.post_processor = TemplateProcessing(\n",
        "    single=\"<sos> $A <eos>\",\n",
        "    special_tokens=[(\"<sos>\", 1), (\"<eos>\", 2)],\n",
        ")\n",
        "trg_tokenizer.post_processor = TemplateProcessing(\n",
        "    single=\"<sos> $A <eos>\",\n",
        "    special_tokens=[(\"<sos>\", 1), (\"<eos>\", 2)],\n",
        ")\n",
        "src_tokenizer.enable_padding(pad_id=0, pad_token=\"<pad>\")\n",
        "trg_tokenizer.enable_padding(pad_id=0, pad_token=\"<pad>\")\n",
        "\n",
        "class BPEDataset(Dataset):\n",
        "    def __init__(self, src_file, trg_file, src_tok, trg_tok, max_len=150):\n",
        "        self.src_data = []\n",
        "        self.trg_data = []\n",
        "        self.src_tok = src_tok\n",
        "        self.trg_tok = trg_tok\n",
        "        self.max_len = max_len\n",
        "\n",
        "        print(f\"Loading data from {src_file}...\")\n",
        "        with open(src_file, 'r', encoding='utf-8') as f: src_lines = f.readlines()\n",
        "        with open(trg_file, 'r', encoding='utf-8') as f: trg_lines = f.readlines()\n",
        "\n",
        "        for src, trg in zip(src_lines, trg_lines):\n",
        "            self.src_data.append(src.strip())\n",
        "            self.trg_data.append(trg.strip())\n",
        "\n",
        "    def __len__(self): return len(self.src_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Tokenizer encode\n",
        "        src_encoded = self.src_tok.encode(self.src_data[index])\n",
        "        trg_encoded = self.trg_tok.encode(self.trg_data[index])\n",
        "\n",
        "        src_ids = torch.tensor(src_encoded.ids)\n",
        "        trg_ids = torch.tensor(trg_encoded.ids)\n",
        "\n",
        "        # Truncate nếu dài\n",
        "        if len(src_ids) > self.max_len: src_ids = src_ids[:self.max_len]\n",
        "        if len(trg_ids) > self.max_len: trg_ids = trg_ids[:self.max_len]\n",
        "\n",
        "        return src_ids, trg_ids\n",
        "\n",
        "def collate_fn(batch):\n",
        "    src_batch, trg_batch = [], []\n",
        "    for src, trg in batch:\n",
        "        src_batch.append(src)\n",
        "        trg_batch.append(trg)\n",
        "\n",
        "    src_batch = torch.nn.utils.rnn.pad_sequence(src_batch, padding_value=0, batch_first=True)\n",
        "    trg_batch = torch.nn.utils.rnn.pad_sequence(trg_batch, padding_value=0, batch_first=True)\n",
        "    return src_batch, trg_batch\n",
        "\n",
        "train_dataset = BPEDataset('data/clean_vi.txt', 'data/clean_en.txt', src_tokenizer, trg_tokenizer)\n",
        "train_iterator = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vC_l15xwSFEg"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class LabelSmoothingLoss(nn.Module):\n",
        "    def __init__(self, classes, padding_idx, smoothing=0.1, dim=-1):\n",
        "        super(LabelSmoothingLoss, self).__init__()\n",
        "        self.confidence = 1.0 - smoothing\n",
        "        self.smoothing = smoothing\n",
        "        self.cls = classes\n",
        "        self.dim = dim\n",
        "        self.padding_idx = padding_idx\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        pred = pred.log_softmax(dim=self.dim)\n",
        "        with torch.no_grad():\n",
        "            true_dist = torch.zeros_like(pred)\n",
        "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
        "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
        "            true_dist[:, self.padding_idx] = 0\n",
        "            mask = (target == self.padding_idx)\n",
        "            if mask.any():\n",
        "                true_dist.masked_fill_(mask.unsqueeze(1), 0.0)\n",
        "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))\n",
        "\n",
        "class NoamScheduler:\n",
        "    def __init__(self, optimizer, d_model, warmup_steps=4000, factor=1.0):\n",
        "        self.optimizer = optimizer\n",
        "        self.d_model = d_model\n",
        "        self.warmup_steps = warmup_steps\n",
        "        self.factor = factor\n",
        "        self.step_num = 0\n",
        "    def step(self):\n",
        "        self.step_num += 1\n",
        "        lr = self.factor * (self.d_model ** -0.5) * min(self.step_num ** -0.5, self.step_num * (self.warmup_steps ** -1.5))\n",
        "        for p in self.optimizer.param_groups: p['lr'] = lr\n",
        "\n",
        "def train_one_epoch(model, iterator, optimizer, criterion, clip, device, scheduler=None):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for i, (src, trg) in enumerate(iterator):\n",
        "        src, trg = src.to(device), trg.to(device)\n",
        "        trg_input = trg[:, :-1]\n",
        "        trg_output = trg[:, 1:]\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, trg_input)\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output.contiguous().view(-1, output_dim)\n",
        "        trg_output = trg_output.contiguous().view(-1)\n",
        "        loss = criterion(output, trg_output)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        if scheduler: scheduler.step()\n",
        "        epoch_loss += loss.item()\n",
        "    return epoch_loss / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851
        },
        "id": "8wZI1yp4SGRu",
        "outputId": "42f915be-7c48-43e1-c414-6ad1f616fd6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training on: cuda\n",
            "Trainable parameters: 59,508,496\n",
            "Starting Phase 3 Training (BPE + Base Model)...\n",
            "Epoch: 01 | Time: 17.9m | Loss: 2.2235\n",
            "  --> Saved Best Model\n",
            "Epoch: 02 | Time: 17.9m | Loss: 2.1003\n",
            "  --> Saved Best Model\n",
            "Epoch: 03 | Time: 17.9m | Loss: 2.0489\n",
            "  --> Saved Best Model\n",
            "Epoch: 04 | Time: 17.9m | Loss: 2.0265\n",
            "  --> Saved Best Model\n",
            "Epoch: 05 | Time: 17.9m | Loss: 2.0026\n",
            "  --> Saved Best Model\n",
            "Epoch: 06 | Time: 17.9m | Loss: 1.9930\n",
            "  --> Saved Best Model\n",
            "Epoch: 07 | Time: 17.9m | Loss: 1.9876\n",
            "  --> Saved Best Model\n",
            "Epoch: 08 | Time: 17.9m | Loss: 1.9689\n",
            "  --> Saved Best Model\n",
            "Epoch: 09 | Time: 17.9m | Loss: 1.9593\n",
            "  --> Saved Best Model\n",
            "Epoch: 10 | Time: 17.9m | Loss: 1.9515\n",
            "  --> Saved Best Model\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Training on: {DEVICE}\")\n",
        "\n",
        "# Vocab size lấy từ BPE tokenizer\n",
        "INPUT_DIM = src_tokenizer.get_vocab_size()\n",
        "OUTPUT_DIM = trg_tokenizer.get_vocab_size()\n",
        "PAD_IDX = 0 \n",
        "\n",
        "D_MODEL = 512   \n",
        "N_HEAD = 8       \n",
        "N_LAYER = 6      \n",
        "D_FF = 2048      \n",
        "DROPOUT = 0.1\n",
        "MAX_LEN = 150\n",
        "\n",
        "model = Transformer(INPUT_DIM, OUTPUT_DIM, D_MODEL, N_HEAD, N_LAYER, D_FF, DROPOUT, MAX_LEN, PAD_IDX, PAD_IDX).to(DEVICE)\n",
        "\n",
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)\n",
        "model.apply(initialize_weights)\n",
        "\n",
        "print(f'Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}')\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005, betas=(0.9, 0.98), eps=1e-9)\n",
        "scheduler = NoamScheduler(optimizer, d_model=D_MODEL, warmup_steps=4000)\n",
        "criterion = LabelSmoothingLoss(classes=OUTPUT_DIM, padding_idx=PAD_IDX, smoothing=0.1)\n",
        "\n",
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "train_losses = []\n",
        "best_loss = float('inf')\n",
        "\n",
        "print(f\"Starting Phase 3 Training (BPE + Base Model)...\")\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    train_loss = train_one_epoch(model, train_iterator, optimizer, criterion, CLIP, DEVICE, scheduler)\n",
        "    end_time = time.time()\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {(end_time-start_time)/60:.1f}m | Loss: {train_loss:.4f}')\n",
        "\n",
        "    if train_loss < best_loss:\n",
        "        best_loss = train_loss\n",
        "        torch.save(model.state_dict(), os.path.join(CHECKPOINT_PATH, 'transformer_phase3_best.pt'))\n",
        "        print(\"  --> Saved Best Model\")\n",
        "\n",
        "plt.plot(train_losses, label='Phase 3 (BPE + Base)')\n",
        "plt.title('Training Loss Phase 3')\n",
        "plt.savefig(os.path.join(PROJECT_PATH, 'loss_phase3.png'))\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
